{
"metadata": {
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": 3
},
"orig_nbformat": 2,
"kernelspec": {
"name": "python_defaultSpec_1596265176831",
"display_name": "Python 3.7.7 64-bit ('machine-learning': conda)"
}
},
"nbformat": 4,
"nbformat_minor": 2,
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Handwritten Digits Recognition by Scikit-Learn, Chainer, PyTorch & Tensorflow+Keras"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Checking available MNIST datasets from each libraries"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### sklearn"
]
},
{
"cell_type": "code",
"execution_count": 22,
"metadata": {},
"outputs": [],
"source": [
"#!pip install sklearn\n",
"from sklearn import datasets"
]
},
{
"cell_type": "code",
"execution_count": 23,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "Shape:  (1797, 64)\n"
}
],
"source": [
"skl_digits = datasets.load_digits()\n",
"# shape of each digit image\n",
"print('Shape: ', skl_digits.data.shape)\n",
"\n",
"# ==> (1797, 64): 1797 * 8x8 image"
]
},
{
"cell_type": "code",
"execution_count": 96,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "array([ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n        9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n       15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n        0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n       16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.])"
},
"metadata": {},
"execution_count": 96
}
],
"source": [
"skl_digits.data[1]"
]
},
{
"cell_type": "code",
"execution_count": 98,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "64"
},
"metadata": {},
"execution_count": 98
}
],
"source": [
"test= [ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n",
"        9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n",
"       15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n",
"        0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n",
"       16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.]\n",
"len(test)"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### chainer"
]
},
{
"cell_type": "code",
"execution_count": 24,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"#!pip install chainer\n",
"import chainer"
]
},
{
"cell_type": "code",
"execution_count": 25,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"train, test = chainer.datasets.get_mnist(withlabel = True, ndim=1)"
]
},
{
"cell_type": "code",
"execution_count": 26,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "# of train data 60000\n# of test data 10000\n"
}
],
"source": [
"print('# of train data',len(train))\n",
"print('# of test data',len(test))"
]
},
{
"cell_type": "code",
"execution_count": 27,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "784"
},
"metadata": {},
"execution_count": 27
}
],
"source": [
"len(train[10][0])\n",
"\n",
"# => 784 = 28*28"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### PyTorch"
]
},
{
"cell_type": "code",
"execution_count": 28,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"#!pip install torch torchvision"
]
},
{
"cell_type": "code",
"execution_count": 29,
"metadata": {},
"outputs": [],
"source": [
"import torchvision.transforms as transforms\n",
"from torch.utils.data import DataLoader\n",
"from torchvision.datasets import MNIST"
]
},
{
"cell_type": "code",
"execution_count": 30,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"data_folder = './torch-data'\n",
"BATCH_SIZE = 8\n",
"\n",
"mnist_data = MNIST(data_folder, train=True, download=True, transform=transforms.ToTensor())\n",
"\n",
"data_loader = DataLoader(mnist_data, batch_size=BATCH_SIZE, shuffle=False)\n"
]
},
{
"cell_type": "code",
"execution_count": 31,
"metadata": {},
"outputs": [],
"source": [
"data_iterator = iter(data_loader)\n",
"images,_ = data_iterator.next()"
]
},
{
"cell_type": "code",
"execution_count": 32,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "torch.Size([1, 28, 28])"
},
"metadata": {},
"execution_count": 32
}
],
"source": [
"images[0].shape\n",
"\n",
"# => 1 * 28 * 28"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### Keras"
]
},
{
"cell_type": "code",
"execution_count": 33,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"#!pip install tensorflow\n",
"#!pip install keras"
]
},
{
"cell_type": "code",
"execution_count": 34,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "(60000, 28, 28)"
},
"metadata": {},
"execution_count": 34
}
],
"source": [
"from keras.datasets import mnist\n",
"\n",
"(train_data, train_teacher_labels), (test_data, test_teacher_labels) = mnist.load_data()\n",
"\n",
"train_data.shape\n",
"\n",
"# 60000 x 28 x 28 "
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Fitting models for MNIST"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### sklearn"
]
},
{
"cell_type": "code",
"execution_count": 37,
"metadata": {},
"outputs": [],
"source": [
"import numpy as np\n",
"import matplotlib.pyplot as plt\n",
"from matplotlib.colors import ListedColormap\n",
"from sklearn.model_selection import train_test_split\n",
"from sklearn.preprocessing import StandardScaler\n",
"from sklearn.datasets import make_moons, make_circles, make_classification\n",
"from sklearn.neural_network import MLPClassifier\n",
"from sklearn.neighbors import KNeighborsClassifier\n",
"from sklearn.svm import SVC\n",
"from sklearn.gaussian_process import GaussianProcessClassifier\n",
"from sklearn.gaussian_process.kernels import RBF\n",
"from sklearn.tree import DecisionTreeClassifier\n",
"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
"from sklearn.naive_bayes import GaussianNB\n",
"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
]
},
{
"cell_type": "code",
"execution_count": 38,
"metadata": {},
"outputs": [],
"source": [
"skl_digits = datasets.load_digits()"
]
},
{
"cell_type": "code",
"execution_count": 41,
"metadata": {},
"outputs": [],
"source": [
"X = skl_digits.data\n",
"y = skl_digits.target"
]
},
{
"cell_type": "code",
"execution_count": 64,
"metadata": {},
"outputs": [],
"source": [
"from sklearn.model_selection import train_test_split\n",
"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
]
},
{
"cell_type": "code",
"execution_count": 65,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "LogisticRegression() \n\nKNeighborsClassifier() \n\nDecisionTreeClassifier() \n\nSVC(kernel='linear') \n\nSVC() \n\nRandomForestClassifier() \n\nPerceptron() \n\nMLPClassifier() \n\n"
}
],
"source": [
"from sklearn.linear_model import LogisticRegression\n",
"from sklearn.neighbors import KNeighborsClassifier\n",
"from sklearn.tree import DecisionTreeClassifier\n",
"from sklearn.svm import SVC\n",
"from sklearn.ensemble import RandomForestClassifier\n",
"from sklearn.linear_model import Perceptron\n",
"from sklearn.neural_network import MLPClassifier\n",
" \n",
"models = []\n",
"models.append((\"LogisticRegression\",LogisticRegression()))\n",
"models.append((\"k-Nearest Neighbors\",KNeighborsClassifier()))\n",
"models.append((\"Decision Tree\",DecisionTreeClassifier()))\n",
"models.append((\"Support Vector Machine(linear)\",SVC(kernel='linear')))\n",
"models.append((\"Support Vector Machine(rbf)\",SVC(kernel='rbf')))\n",
"models.append((\"Random Forest\",RandomForestClassifier()))\n",
"models.append((\"Perceptron\",Perceptron()))\n",
"models.append((\"Multilayer Perceptron\",MLPClassifier()))\n",
" \n",
"names = []\n",
"results = []\n",
"for name, model in models:\n",
"    \n",
"    print(model.fit(X_train,y_train),\"\\n\")\n",
"    \n",
"    names.append(name)\n",
"    results.append(model.score(X_test,y_test))"
]
},
{
"cell_type": "code",
"execution_count": 66,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "                       Classifier     Score\n4     Support Vector Machine(rbf)  0.991111\n1             k-Nearest Neighbors  0.980000\n3  Support Vector Machine(linear)  0.971111\n5                   Random Forest  0.971111\n7           Multilayer Perceptron  0.971111\n0              LogisticRegression  0.951111\n6                      Perceptron  0.926667\n2                   Decision Tree  0.835556",
"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Classifier</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Support Vector Machine(rbf)</td>\n      <td>0.991111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>k-Nearest Neighbors</td>\n      <td>0.980000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Support Vector Machine(linear)</td>\n      <td>0.971111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Random Forest</td>\n      <td>0.971111</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Multilayer Perceptron</td>\n      <td>0.971111</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.951111</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Perceptron</td>\n      <td>0.926667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Decision Tree</td>\n      <td>0.835556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
},
"metadata": {},
"execution_count": 66
}
],
"source": [
"import pandas as pd\n",
"summary = pd.DataFrame(columns=['Classifier', 'Score'])\n",
"\n",
"for i in range(len(names)):\n",
"    summary = summary.append(pd.Series( [names[i],results[i]], index=summary.columns ), ignore_index=True)\n",
" \n",
"summary.sort_values(by='Score', ascending=False)"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"By initial comparison, SVM(rbf) has the best performance on score.\n",
"Now using grid-search to find the optimal parameters"
]
},
{
"cell_type": "code",
"execution_count": 67,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "GridSearchCV(cv=5, estimator=SVC(),\n             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n                         'gamma': [0.001, 0.01, 0.1, 1, 10, 100]})"
},
"metadata": {},
"execution_count": 67
}
],
"source": [
"from sklearn.model_selection import GridSearchCV\n",
"\n",
"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],  'gamma' : [0.001, 0.01, 0.1, 1, 10, 100]}\n",
"\n",
"grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
"\n",
"# fit 関数を呼ぶことで交差検証とグリッドサーチがどちらも実行される\n",
"grid_search.fit(X_train, y_train)"
]
},
{
"cell_type": "code",
"execution_count": 68,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "Test set score: 0.9933333333333333\nBest parameters: {'C': 10, 'gamma': 0.001}\nBest cross-validation: 0.9918353297535452\n"
}
],
"source": [
"print('Test set score: {}'.format(grid_search.score(X_test, y_test)))\n",
"print('Best parameters: {}'.format(grid_search.best_params_))\n",
"print('Best cross-validation: {}'.format(grid_search.best_score_))"
]
},
{
"cell_type": "code",
"execution_count": 69,
"metadata": {},
"outputs": [
{
"output_type": "execute_result",
"data": {
"text/plain": "SVC(C=10, gamma=0.001)"
},
"metadata": {},
"execution_count": 69
}
],
"source": [
"model = SVC(C=10, gamma=0.001)\n",
"model.fit(X_train, y_train)"
]
},
{
"cell_type": "code",
"execution_count": 70,
"metadata": {},
"outputs": [],
"source": [
"predicted = model.predict(X_test)"
]
},
{
"cell_type": "code",
"execution_count": 72,
"metadata": {},
"outputs": [],
"source": [
"from sklearn.metrics import confusion_matrix, classification_report"
]
},
{
"cell_type": "code",
"execution_count": 74,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        37\n           1       0.98      1.00      0.99        43\n           2       1.00      1.00      1.00        44\n           3       1.00      1.00      1.00        45\n           4       1.00      1.00      1.00        38\n           5       0.98      0.98      0.98        48\n           6       1.00      1.00      1.00        52\n           7       1.00      1.00      1.00        48\n           8       1.00      0.98      0.99        48\n           9       0.98      0.98      0.98        47\n\n    accuracy                           0.99       450\n   macro avg       0.99      0.99      0.99       450\nweighted avg       0.99      0.99      0.99       450\n\n"
}
],
"source": [
"print(classification_report(y_test, predicted))"
]
},
{
"cell_type": "code",
"execution_count": 75,
"metadata": {
"tags": []
},
"outputs": [
{
"output_type": "stream",
"name": "stdout",
"text": "[[37  0  0  0  0  0  0  0  0  0]\n [ 0 43  0  0  0  0  0  0  0  0]\n [ 0  0 44  0  0  0  0  0  0  0]\n [ 0  0  0 45  0  0  0  0  0  0]\n [ 0  0  0  0 38  0  0  0  0  0]\n [ 0  0  0  0  0 47  0  0  0  1]\n [ 0  0  0  0  0  0 52  0  0  0]\n [ 0  0  0  0  0  0  0 48  0  0]\n [ 0  1  0  0  0  0  0  0 47  0]\n [ 0  0  0  0  0  1  0  0  0 46]]\n"
}
],
"source": [
"print(confusion_matrix(y_test, predicted))"
]
},
{
"cell_type": "code",
"execution_count": 76,
"metadata": {},
"outputs": [],
"source": [
"import pickle"
]
},
{
"cell_type": "code",
"execution_count": 87,
"metadata": {},
"outputs": [],
"source": [
"pickle.dump(model, open('../models/sklearn.pickle','wb'))"
]
},
{
"cell_type": "code",
"execution_count": 91,
"metadata": {},
"outputs": [],
"source": [
"del model\n",
"model = pickle.load(open('../models/sklearn.pickle', 'rb'))"
]
}
]
}